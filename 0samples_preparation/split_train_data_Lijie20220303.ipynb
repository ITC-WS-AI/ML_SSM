{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcb18148-ff00-4db1-a24a-02676f92b605",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extract independent stations (not used for training).\n",
    "**predictors**:\n",
    "\n",
    "| name | Meaning | unit | New Name |\n",
    "| --- | --- | --- | --- |\n",
    "| EVI_SG_linear | Enhanced Vegetation Index | - | EVI|\n",
    "| Evapo | Evaporation | m |\n",
    "| LST_DAILY | daily land surface temperature | degree Celcius |LST_Daily |\n",
    "| TI | Topographic index | - |\n",
    "| Tair | Air tempereature (2m) | Degree Celcius | T_air |\n",
    "| api | Antecedent Precipitation Index | - | API |\n",
    "| clay, sand, silt | soil texture | % | Clay, Sand, Silt | \n",
    "| soil moisture | Volumetric soil moisture | cm3/cm3 | Soil Moisture |\n",
    "| Preci | Precipitation | mm |\n",
    "| porosity | Soil Porosity | - | Porosity |\n",
    "| Date | YYYY-MM-DD | - |\n",
    "| elevation | Elevation | m |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2bd7c6fa-015a-4f45-a3e8-ebf988a5e532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['EVI_SG_linear', 'Evapo', 'LST_DAILY', 'LST_Diff', 'NDVI_SG_linear',\n",
      "       'TI', 'Tair', 'api', 'clay', 'date', 'elevation', 'lat', 'lon',\n",
      "       'network', 'omc', 'porosity', 'sand', 'silt', 'soil moisture',\n",
      "       'station', 'Preci'],\n",
      "      dtype='object')\n",
      "Index(['EVI_SG_linear', 'Evapo', 'LST_DAILY', 'LST_Diff', 'NDVI_SG_linear',\n",
      "       'TI', 'Tair', 'api', 'clay', 'date', 'elevation', 'esa_cci', 'lat',\n",
      "       'lon', 'network', 'omc', 'porosity', 'sand', 'silt', 'soil moisture',\n",
      "       'station', 'Preci'],\n",
      "      dtype='object')\n",
      "Number of networks for the training data:  48\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "--------------------------\n",
    "File Name:  prepare_data.py\n",
    "Author: zhang (FZJ/IBG3)\n",
    "Contact: leojayak@gmail.com\n",
    "Date: 02.03.22\n",
    "\n",
    "Description: Prepare the data for training and testing.\n",
    "--------------------------\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "os.chdir('/p/home/jusers/zhang23/juwels/SSM')\n",
    "# os.chdir('/home/zhang/SSM/')\n",
    "file_train = 'train.csv'\n",
    "file_validate = 'validate.csv'\n",
    "\n",
    "# output\n",
    "folder_output = 'output'\n",
    "if not os.path.exists(folder_output):\n",
    "    os.mkdir(folder_output)\n",
    "df_out_train = pd.DataFrame()\n",
    "df_out_validate = pd.DataFrame()\n",
    "\n",
    "scale_factor = 0.1  # Determine the proportion of data not used in the training.\n",
    "\n",
    "df_train = pd.read_csv(file_train, index_col=0)\n",
    "df_validate = pd.read_csv(file_validate, index_col=0)\n",
    "\n",
    "# remove the LST < 0.\n",
    "df_lst_le_0_train = df_train[df_train['LST_DAILY'] < 0]\n",
    "df_train = df_train.drop(df_lst_le_0_train.index, axis=0)\n",
    "\n",
    "df_lst_le_0_validate = df_validate[df_validate['LST_DAILY'] < 0]\n",
    "df_validate = df_validate.drop(df_lst_le_0_validate.index, axis=0)\n",
    "\n",
    "# Remove 'ID'\n",
    "df_train = df_train.drop('ID', axis=1)\n",
    "df_validate = df_validate.drop('ID', axis=1)\n",
    "\n",
    "print(df_train.columns)\n",
    "print(df_validate.columns)\n",
    "train_column_list = ['EVI', 'Evapo', 'LST_Daily', 'LST_Diff', 'NDVI', 'TI', 'T_air', 'API', \n",
    "               'Clay', 'Date', 'Elevation', 'lat', 'lon', 'network', 'OMC',\n",
    "               'Porosity', 'Sand', 'Silt', 'Soil Moisture', 'station', 'Preci']\n",
    "\n",
    "validate_columns_list = ['EVI', 'Evapo', 'LST_Daily', 'LST_Diff', 'NDVI', 'TI', 'T_air', 'API', \n",
    "               'Clay', 'Date', 'Elevation', 'ESA-CCI', 'lat', 'lon', 'network', 'OMC',\n",
    "               'Porosity', 'Sand', 'Silt', 'Soil Moisture', 'station', 'Preci']\n",
    "\n",
    "df_train.columns = train_column_list\n",
    "df_validate.columns = validate_columns_list\n",
    "\n",
    "# Get the networks from the training data.\n",
    "networks = df_validate['network'].drop_duplicates()\n",
    "print('Number of networks for the training data: ', len(networks))\n",
    "\n",
    "df_excluded_station = pd.DataFrame(columns=['network', 'station', 'train_size','validate_size', 'lon', 'lat'], dtype='object')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d203d4b5-9f9a-4c7d-9b96-474ae2d5830e",
   "metadata": {},
   "source": [
    "### Rename predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e7870027-b4ba-4d95-a189-f409dd4cc7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['EVI', 'Evapo', 'LST_Daily', 'LST_Diff', 'NDVI', 'TI', 'T_air', 'API',\n",
      "       'Clay', 'Date', 'Elevation', 'lat', 'lon', 'network', 'OMC', 'Porosity',\n",
      "       'Sand', 'Silt', 'Soil Moisture', 'station', 'Preci'],\n",
      "      dtype='object')\n",
      "Index(['EVI', 'Evapo', 'LST_Daily', 'LST_Diff', 'NDVI', 'TI', 'T_air', 'API',\n",
      "       'Clay', 'Date', 'Elevation', 'ESA-CCI', 'lat', 'lon', 'network', 'OMC',\n",
      "       'Porosity', 'Sand', 'Silt', 'Soil Moisture', 'station', 'Preci'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_train.columns)\n",
    "print(df_validate.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7dd97f69-2010-418e-a677-a983bebc0d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 FMI number of stations: 18, number of exclude stations: 1, 1\n",
      "1 GTK number of stations: 5, number of exclude stations: 0, 0\n",
      "2 VAS number of stations: 2, number of exclude stations: 0, 0\n",
      "3 AWDN number of stations: 45, number of exclude stations: 4, 4\n",
      "4 HOBE number of stations: 30, number of exclude stations: 3, 3\n",
      "5 MAQU number of stations: 19, number of exclude stations: 1, 1\n",
      "6 RSMN number of stations: 10, number of exclude stations: 1, 1\n",
      "7 SCAN number of stations: 189, number of exclude stations: 18, 18\n",
      "8 SKKU number of stations: 3, number of exclude stations: 0, 0\n",
      "9 WSMN number of stations: 6, number of exclude stations: 0, 0\n",
      "10 iRON number of stations: 7, number of exclude stations: 0, 0\n",
      "11 DAHRA number of stations: 1, number of exclude stations: 0, 0\n",
      "12 OZNET number of stations: 34, number of exclude stations: 3, 3\n",
      "13 RISMA number of stations: 21, number of exclude stations: 2, 2\n",
      "14 USCRN number of stations: 102, number of exclude stations: 10, 10\n",
      "15 COSMOS number of stations: 89, number of exclude stations: 8, 8\n",
      "16 ORACLE number of stations: 6, number of exclude stations: 0, 0\n",
      "17 SNOTEL number of stations: 408, number of exclude stations: 40, 40\n",
      "18 SW-WHU number of stations: 4, number of exclude stations: 0, 0\n",
      "19 TERENO number of stations: 5, number of exclude stations: 0, 0\n",
      "20 UMBRIA number of stations: 13, number of exclude stations: 1, 1\n",
      "21 UMSUOL number of stations: 1, number of exclude stations: 0, 0\n",
      "22 FR-Aqui number of stations: 4, number of exclude stations: 0, 0\n",
      "23 KHOREZM number of stations: 2, number of exclude stations: 0, 0\n",
      "24 MOL-RAO number of stations: 2, number of exclude stations: 0, 0\n",
      "25 PBO-H2O number of stations: 142, number of exclude stations: 14, 14\n",
      "26 BNZ-LTER number of stations: 11, number of exclude stations: 1, 1\n",
      "27 CALABRIA number of stations: 2, number of exclude stations: 0, 0\n",
      "28 CAMPANIA number of stations: 2, number of exclude stations: 0, 0\n",
      "29 MONGOLIA number of stations: 11, number of exclude stations: 1, 1\n",
      "30 REMEDHUS number of stations: 14, number of exclude stations: 1, 1\n",
      "31 UDC-SMOS number of stations: 9, number of exclude stations: 0, 0\n",
      "32 USDA-ARS number of stations: 2, number of exclude stations: 0, 0\n",
      "33 CTP-SMTMN number of stations: 57, number of exclude stations: 5, 5\n",
      "34 SMOSMANIA number of stations: 11, number of exclude stations: 1, 1\n",
      "35 SOILSCAPE number of stations: 150, number of exclude stations: 15, 15\n",
      "36 AMMA-CATCH number of stations: 7, number of exclude stations: 0, 0\n",
      "37 IIT-KANPUR number of stations: 1, number of exclude stations: 0, 0\n",
      "38 WEGENERNET number of stations: 12, number of exclude stations: 1, 1\n",
      "39 BIEBRZA-S-1 number of stations: 22, number of exclude stations: 2, 2\n",
      "40 CARBOAFRICA number of stations: 1, number of exclude stations: 0, 0\n",
      "41 SWEX-POLAND number of stations: 6, number of exclude stations: 0, 0\n",
      "42 HiWATER-EHWSN number of stations: 169, number of exclude stations: 16, 16\n",
      "43 HSC-SELMACHEON number of stations: 1, number of exclude stations: 0, 0\n",
      "44 FLUXNET-AMERIFLUX number of stations: 1, number of exclude stations: 0, 0\n",
      "45 HYDROL-NET-PERUGIA number of stations: 2, number of exclude stations: 0, 0\n",
      "46 ARM number of stations: 25, number of exclude stations: 2, 2\n",
      "47 ICN number of stations: 13, number of exclude stations: 1, 1\n"
     ]
    }
   ],
   "source": [
    "# Loops to get the station information in each network.\n",
    "for idx_i, network in enumerate(networks):\n",
    "    # dataframe for the network.\n",
    "    df_network_train = df_train[df_train['network'] == network]\n",
    "    df_network_validate = df_validate[df_validate['network'] == network]\n",
    "\n",
    "    stations = df_network_validate['station'].drop_duplicates()  # Get the stations.\n",
    "    n_stations = len(stations)  # Number of stations in the network.\n",
    "\n",
    "    # excluded stations.\n",
    "    n_excluded_stations = int(n_stations * scale_factor)\n",
    "    excluded_stations = stations.values[np.random.choice(range(n_stations), n_excluded_stations)]\n",
    "    print(idx_i, network,\n",
    "          f'number of stations: {n_stations}, number of exclude stations: {n_excluded_stations}, {len(excluded_stations)}')\n",
    "\n",
    "    # Remove the excluded data.\n",
    "    df_network_train = df_network_train.set_index('station')\n",
    "    df_network_train = df_network_train.drop(excluded_stations)\n",
    "\n",
    "    df_network_validate = df_network_validate.set_index('station')\n",
    "    df_network_validate = df_network_validate.drop(excluded_stations)\n",
    "\n",
    "    # Save the excluded stations into a separate file.\n",
    "    for idx_j, station in enumerate(excluded_stations):\n",
    "        df_station_train = df_train[df_train['station'] == station]\n",
    "        df_station_validate = df_validate[df_validate['station'] == station]\n",
    "        df_station = pd.concat([df_station_train, df_station_validate])\n",
    "        df_station.to_csv(os.path.join(folder_output, f'Independent_{network}_{station}.csv'))\n",
    "        \n",
    "        # collect process information.\n",
    "        s_excluded_station = pd.Series(index=['network', 'station', 'train_size', 'validate_size','lon', 'lat'], dtype='object')\n",
    "        s_excluded_station['network'] = network\n",
    "        s_excluded_station['station'] = station\n",
    "        s_excluded_station['train_size'] = len(df_station_train)\n",
    "        s_excluded_station['validate_size'] = len(df_station_validate)\n",
    "        s_excluded_station['lon'] = df_station_train['lon'].iloc[0]\n",
    "        s_excluded_station['lat'] = df_station_train['lat'].iloc[0]\n",
    "\n",
    "        df_excluded_station = df_excluded_station.append(s_excluded_station, ignore_index=True)\n",
    "\n",
    "    df_out_train = df_out_train.append(df_network_train)\n",
    "    df_out_validate = df_out_validate.append(df_network_validate)\n",
    "\n",
    "df_out_train.to_csv('ML_training&testing_v01_20220303.csv')\n",
    "df_out_validate.to_csv('ML_validating_v01_20220303.csv')\n",
    "df_excluded_station.to_csv('Excluded_station_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "13e59fa2-ad20-446d-9d2e-c29d1f6c2ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['station', 'EVI', 'Evapo', 'LST_Daily', 'LST_Diff', 'NDVI', 'TI',\n",
       "       'T_air', 'API', 'Clay', 'Date', 'Elevation', 'lat', 'lon', 'network',\n",
       "       'OMC', 'Porosity', 'Sand', 'Silt', 'Soil Moisture', 'Preci'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ML_training&testing_v01_20220303.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ad0b3b44-61db-4201-bf3e-21193d9d4095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels = df['Soil Moisture']\n",
    "df = df.drop('Soil Moisture', axis=1)\n",
    "feature_list = df.columns\n",
    "features = np.array(df)\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.25,\n",
    "                                                                 random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ce9db130-3599-4991-a61c-8cb0bca46839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(352075, 20)\n",
      "(117359, 20)\n",
      "(352075,)\n",
      "(117359,)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9a9bab9-4dbe-4be1-ad6c-89e48b7afd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EVI_SG_linear       0.0818455\n",
       "Evapo             -0.00134076\n",
       "ID                      61018\n",
       "LST_DAILY                4.95\n",
       "LST_Diff                 5.36\n",
       "NDVI_SG_linear       0.247624\n",
       "TI                    9.72459\n",
       "Tair                  6.91391\n",
       "api                   17.2963\n",
       "clay                      9.4\n",
       "date               2013-05-20\n",
       "elevation             468.604\n",
       "lat                   68.3302\n",
       "lon                   27.5506\n",
       "network                   FMI\n",
       "omc                   37.6694\n",
       "porosity             0.762264\n",
       "sand                     55.5\n",
       "silt                     35.1\n",
       "Preci             0.000852346\n",
       "Name: SAA111, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
